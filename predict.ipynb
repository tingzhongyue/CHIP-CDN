{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4e0576-7f3c-49be-93cb-fc27f311cc04",
   "metadata": {},
   "source": [
    "导入所需包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b702c114-67fa-4524-b240-b99a626577a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from loguru import logger\n",
    "from scipy.stats import spearmanr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87bbe67-0f76-4d7a-932f-2884611882f8",
   "metadata": {},
   "source": [
    "与data_process相同，进行数据清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4820060-1c70-41ca-83e3-0f332971fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_map = {'＋': '+',\n",
    " 'pci': '经皮冠状动脉介入治疗',\n",
    " 'cad': '冠状动脉性心脏病',\n",
    " 'sle': '系统性红斑狼疮',\n",
    " 'loa': '左枕前胎位',\n",
    " 'mp': '支原体',\n",
    " 'ou': '双眼',\n",
    " 'mt': '恶性肿瘤',\n",
    " 'paget': '佩吉特',\n",
    " 'tpsa': '肿瘤标志物',\n",
    " 'tc': '血清总胆固醇',\n",
    " 'pbc': '原发性胆汁型肝硬化',\n",
    " 'fgr': '胎儿生长受限',\n",
    " 'barrett': '巴氏',\n",
    " 'tia': '短暂性脑缺血发作',\n",
    " 'bowen': '鲍恩',\n",
    " 'as': '强直性脊柱炎',\n",
    " 'dic': '弥散性血管内凝血',\n",
    " 'hcc': '肝细胞癌',\n",
    " 'ggo': '肺部阴影',\n",
    " 'cushing': '库欣',\n",
    " 'ln': '狼疮性肾炎',\n",
    " 'prl': '泌乳素',\n",
    " 'copd': '慢性阻塞性肺疾病',\n",
    " 'mia': '微浸润性腺癌',\n",
    " 'cea': '癌胚抗原',\n",
    " 'hpv': '人乳头瘤病毒感染',\n",
    " 'carcinoma': '恶性上皮肿瘤',\n",
    " 'iud': '具有子宫内避孕装置',\n",
    " 'aecopd': '急性加重期慢性阻塞性肺疾病',\n",
    " 'gvhd': '移植物抗宿主病',\n",
    " 'crohn': '克罗恩',\n",
    " 'dixon': '直肠切除术',\n",
    " 'tsh': '促甲状腺激素',\n",
    " 'ptca': '冠状动脉腔内血管成形术',\n",
    " 'ivf': '人工妊娠',\n",
    " 'rop': '早产儿视网膜病',\n",
    " 'avnrt': '房室结折返性心动过速',\n",
    " 'cg': '慢性胃炎',\n",
    " 'avn': '成人股骨头缺血性坏死',\n",
    " 'rca': '右冠状动脉',\n",
    " 'nt': '颈部透明度厚度',\n",
    " 'nerd': '非糜烂性胃食管反流病',\n",
    " 'sonk': '自发性膝关节骨坏死',\n",
    " 'cabg': '冠状动脉搭桥',\n",
    " 'burrkitt': '伯基特',\n",
    " 'chd': '冠状动脉粥样硬化性心脏病',\n",
    " 'hf': '心力衰竭',\n",
    " 'chdhf': '冠心病心力衰竭',\n",
    " 'ep': '癫痫',\n",
    " 'simmond': '西蒙',\n",
    " 'mgd': '睑板腺功能障碍',\n",
    " 'fl': '滤泡性淋巴瘤',\n",
    " 'teson': '特尔松',\n",
    " 'ra': '类风湿性关节炎',\n",
    " 'gd': '毒性弥漫性甲状腺肿',\n",
    " 'poland': '波兰',\n",
    " 'eb': '疱疹病毒',\n",
    " 'msi': '微卫星不稳定',\n",
    " 'pnet': '原始性神经外胚瘤',\n",
    " 'lutembacher': '卢滕巴赫',\n",
    " 'acl': '膝关节前交叉韧带',\n",
    " 'he': '人附睾蛋白',\n",
    " 'vkh': '伏格特-小柳-原田',\n",
    " 'le': '红斑狼疮',\n",
    " 'nyha': '纽约心脏病协会',\n",
    " 'kt': '克利佩尔-特农纳',\n",
    " 'rhcc': '复发性肝癌',\n",
    " 'ige': '免疫球蛋白E',\n",
    " 'poncet': '篷塞',\n",
    " 'lst': '大肠侧向发育型肿瘤',\n",
    " 'cgn': '慢性肾小球肾炎',\n",
    " 'fsgs': '局灶节段性肾小球硬化',\n",
    " 'gdm': '妊娠期糖尿病',\n",
    " 'rsa': '右骶前',\n",
    " 'htn': '高血压',\n",
    " 'ncr': '接近完全缓解',\n",
    " 'hunt': '亨特',\n",
    " 'ddd': '退变性椎间盘病',\n",
    " 'alzheimer': '阿尔茨海默',\n",
    " 'nsclc': '非小细胞肺腺癌',\n",
    " 'evens': '伊文氏',\n",
    " 'mikulicz': '米库利奇',\n",
    " 'ev': '肠病毒',\n",
    " 'igd': '免疫球蛋白D',\n",
    " 'chf': '充血性心力衰竭',\n",
    " 'od': '右眼',\n",
    " 'ipi': '国际预后指数',\n",
    " 'dieulafoy': '迪厄拉富瓦',\n",
    " 'lad': '左前降支',\n",
    " 'ao': '主动脉',\n",
    " 'hoffa': '霍法',\n",
    " 'tunner': '特纳',\n",
    " 'pagtes': '佩吉特',\n",
    " 'killip': '基利普',\n",
    " 'addison': '艾迪生',\n",
    " 'rett': '雷特',\n",
    " 'wernicke': '韦尼克',\n",
    " 'castelman': '卡斯尔曼',\n",
    " 'goldenhar': '戈尔登哈尔',\n",
    " 'ufh': '普通肝素',\n",
    " 'ddh': '发育性髋关节发育不良',\n",
    " 'stevens': '史蒂文斯',\n",
    " 'johnson': '约翰逊',\n",
    " 'athmas': '哮喘',\n",
    " 'rfa': '射频消融',\n",
    " 'kippip': '基利普',\n",
    " 'pancreaticcancer': '胰腺恶性肿瘤',\n",
    " 'srs': '立体定向放射外科',\n",
    " 'ama': '抗线粒体抗体',\n",
    " 'cgd': '慢性肉芽肿病',\n",
    " 'bmt': '骨髓移植',\n",
    " 'sd': '脐带血流比值',\n",
    " 'arnold': '阿诺德',\n",
    " 'tb': '结核感染',\n",
    " 'dvt': '下肢深静脉血栓形成',\n",
    " 'sturge': '斯特奇',\n",
    " 'weber': '韦伯',\n",
    " 'smt': '黏膜下肿瘤',\n",
    " 'ca': '恶性肿瘤',\n",
    " 'smtca': '粘膜下恶性肿瘤',\n",
    " 'nse': '神经元特异性烯醇化酶',\n",
    " 'psvt': '阵发性室上性心动过速',\n",
    " 'gaucher': '戈谢',\n",
    " 'fai': '髋关节撞击综合征',\n",
    " 'lop': '左枕后位',\n",
    " 'lot': '左枕横位',\n",
    " 'pcos': '多囊卵巢综合征',\n",
    " 'sweet': '急性发热性嗜中性皮病',\n",
    " 'graves': '格雷夫斯',\n",
    " 'cdh': '先天性髋关节脱位',\n",
    " 'enneking': '恩内金',\n",
    " 'leep': '利普',\n",
    " 'itp': '特发性血小板减少性紫癜',\n",
    " 'wbc': '白细胞',\n",
    " 'malt': '粘膜相关淋巴样组织',\n",
    " 'naoh': '氢氧化钠',\n",
    " 'fd': '功能性消化不良',\n",
    " 'ck': '肌酸激酶',\n",
    " 'hl': '霍奇金淋巴瘤',\n",
    " 'chb': '慢性乙型肝炎',\n",
    " 'est': '内镜下十二指肠乳头括约肌切开术',\n",
    " 'enbd': '内镜下鼻胆管引流术',\n",
    " 'carolis': '卡罗利斯',\n",
    " 'lam': '淋巴管肌瘤病',\n",
    " 'ptcd': '经皮肝穿刺胆道引流术',\n",
    " 'alk': '间变性淋巴瘤激酶',\n",
    " 'hunter': '亨特',\n",
    " 'pof': '卵巢早衰',\n",
    " 'ems': '子宫内膜异位症',\n",
    " 'asd': '房间隔缺损',\n",
    " 'vsd': '室间隔缺损',\n",
    " 'pda': '动脉导管未闭',\n",
    " 'stills': '斯蒂尔',\n",
    " 'ecog': '东部癌症协作组',\n",
    " 'castlemen': '卡斯尔曼',\n",
    " 'cgvhd': '慢性移植物抗宿主病',\n",
    " 'ards': '急性呼吸窘迫综合征',\n",
    " 'op': '骨质疏松',\n",
    " 'lsa': '左骶前',\n",
    " 'afp': '甲胎蛋白',\n",
    " 'sclc': '小细胞癌',\n",
    " 'ecg': '心电图',\n",
    " 'pdl': '细胞程序性死亡配体',\n",
    " 'mss': '微卫星稳定',\n",
    " 'masson': '马松',\n",
    " 'ms': '多发性硬化',\n",
    " 'tg': '甘油三酯',\n",
    " 'cmt': '腓骨肌萎缩',\n",
    " 'ph': '氢离子浓度指数',\n",
    " 'dlbcl': '弥漫大B细胞淋巴瘤',\n",
    " 'turner': '特纳',\n",
    " 'aml': '急性骨髓系白血病',\n",
    " 'pta': '经皮血管腔内血管成形术',\n",
    " 'alpers': '阿尔珀斯',\n",
    " 'tat': '破伤风抗毒素',\n",
    " 'cavc': '完全性房室间隔缺损',\n",
    " 'coa': '主动脉缩窄',\n",
    " 'ggt': '谷氨酰转肽酶',\n",
    " 'edss': '扩展残疾状态量表',\n",
    " 'vin': '外阴上皮内瘤变',\n",
    " 'vini': '外阴上皮内瘤变1',\n",
    " 'vinii': '外阴上皮内瘤变2',\n",
    " 'viniii': '外阴上皮内瘤变3',\n",
    " 'ebv': '疱疹病毒',\n",
    " 'dcis': '乳腺导管原位癌',\n",
    " 'gu': '胃溃疡',\n",
    " 'terson': '特尔松',\n",
    " 'oa': '骨关节炎',\n",
    " 'cin': '宫颈上皮内瘤变'\n",
    "}\n",
    "i_to_num_dict = {'i':'1', 'ii':'2', 'iii':'3', 'iv':'4', 'v':'5', 'vi':'6', 'vii':'7', 'viii':'8'}\n",
    "digit_map = {\"Ⅳ\":\"iv\", \"Ⅲ\":\"iii\", \"Ⅱ\":\"ii\", \"Ⅰ\":\"i\", \"一\":\"1\", \"二\":\"2\", \"三\":\"3\", \"四\":\"4\", \"五\":\"5\", \"六\":\"6\"}\n",
    "greek_lower = [chr(ch) for ch in range(945, 970) if ch != 962]\n",
    "greek_upper = [chr(ch) for ch in range(913, 937) if ch != 930]\n",
    "greek_englist = [\"alpha\", \"beta\", \"gamma\", \"delta\", \"epsilon\", \"zeta\", \"eta\", \"theta\", \"iota\", \"kappa\", \"lambda\",\n",
    "                 \"mu\", \"nu\", \"xi\", \"omicron\", \"pi\", \"rho\", \"sigma\", \"tau\", \"upsilon\", \"phi\", \"chi\", \"psi\", \"omega\"]\n",
    "greek_map = {ch:greek_englist[idx % 24] for idx, ch in enumerate(greek_lower + greek_upper)}\n",
    "prefix_suffix_src = [\"部位未特指的\", \"未特指的\", \"原因不明的\", \"意图不确定的\", \"不可归类在他处\", \"其他特指的疾患\"]\n",
    "prefix_suffix_tgt = [\"部未指\", \"未指\", \"不明\", \"意不\", \"不归他\", \"他特指\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcbc811-a421-4354-b17f-240751c2fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_digit(string):\n",
    "    new_string = \"\"\n",
    "    for ch in string:\n",
    "        if ch.upper() in digit_map:\n",
    "            new_string = new_string + digit_map[ch.upper()]\n",
    "        else:\n",
    "            new_string = new_string + ch\n",
    "    return new_string\n",
    "\n",
    "def clean_greek(string):\n",
    "    new_string = \"\"\n",
    "    for ch in string:\n",
    "        if ch in greek_map:\n",
    "            new_string = new_string + greek_map[ch]\n",
    "        else:\n",
    "            new_string = new_string + ch\n",
    "    return new_string\n",
    "\n",
    "def clean_prefix_suffix(string):\n",
    "    for idx, replace_str in enumerate(prefix_suffix_src):\n",
    "        string = string.replace(replace_str, prefix_suffix_tgt[idx])\n",
    "    return string\n",
    "\n",
    "def match(substring):\n",
    "    abbr = re.search('[a-z]+', substring.groupdict()['pat']).group()\n",
    "    matched = re.sub(abbr, other_map[abbr], substring.groupdict()['pat'])\n",
    "    return matched\n",
    "\n",
    "def clean_other(string):\n",
    "    for item in list(other_map.keys()):\n",
    "        if item == \"＋\":\n",
    "            string = re.sub(item, other_map[item], ' '+string+' ')\n",
    "        else:\n",
    "            string = re.sub('(?P<pat>[^a-zA-Z]'+item+'[^a-zA-Z])', match, ' '+string+' ')\n",
    "    return string.strip(' ')\n",
    "\n",
    "def clean_index(string):\n",
    "    # 1. 2.\n",
    "    new_string = \"\"\n",
    "    idx = 0\n",
    "    while idx < len(string):\n",
    "        ch = string[idx]\n",
    "        if \"0\" <= ch <= \"9\" and idx < len(string) - 1 and string[idx + 1] == \".\":\n",
    "            new_string += \" \"\n",
    "            idx += 1\n",
    "        else:\n",
    "            new_string += ch\n",
    "        idx += 1\n",
    "    return new_string\n",
    "\n",
    "def match_itomun(substring):\n",
    "    abbr = re.search('^v?i+v?', substring.groupdict()['pat'])\n",
    "    if not abbr:\n",
    "        abbr = re.search('v?i+v?$', substring.groupdict()['pat'])\n",
    "    if not abbr:\n",
    "        return substring.group()\n",
    "    else:\n",
    "        abbr = abbr.group()\n",
    "        matched = re.sub(abbr, i_to_num_dict[abbr], substring.groupdict()['pat'])\n",
    "        return matched\n",
    "    \n",
    "def i_to_num(string):\n",
    "    if 'i' in string:\n",
    "        string = re.sub('(?P<pat>[a-zA-Z]+)', match_itomun, string)\n",
    "    return string\n",
    "\n",
    "def clean(string):\n",
    "    string = string.replace(\"\\\"\", \" \").lower()\n",
    "    string = clean_index(string)\n",
    "    string = clean_prefix_suffix(string)\n",
    "    string = clean_greek(string)\n",
    "    string = clean_digit(string)\n",
    "    string = clean_other(string)\n",
    "    string = i_to_num(string)\n",
    "    string = clean_other(string)\n",
    "    return string.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de411b-ba87-4a10-8ed3-78bc60c76bff",
   "metadata": {},
   "source": [
    "BM25算法进行初步筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45826c8-0920-42ee-b6e7-b4ae9cbeb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25_Model(object):\n",
    "    def __init__(self, documents_list, k1=2, k2=1, b=0.5):\n",
    "        self.documents_list = documents_list\n",
    "        self.documents_number = len(documents_list)\n",
    "        self.avg_documents_len = sum([len(document) for document in documents_list]) / self.documents_number\n",
    "        self.f = []\n",
    "        self.idf = {}\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.b = b\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        df = {}\n",
    "        for document in self.documents_list:\n",
    "            temp = {}\n",
    "            for word in document:\n",
    "                temp[word] = temp.get(word, 0) + 1\n",
    "            self.f.append(temp)\n",
    "            for key in temp.keys():\n",
    "                df[key] = df.get(key, 0) + 1\n",
    "        for key, value in df.items():\n",
    "            self.idf[key] = np.log((self.documents_number - value + 0.5) / (value + 0.5))\n",
    "\n",
    "    def get_score(self, index, query):\n",
    "        score = 0.0\n",
    "        document_len = len(self.f[index])\n",
    "        qf = Counter(query)\n",
    "        for q in query:\n",
    "            if q not in self.f[index]:\n",
    "                continue\n",
    "            score += self.idf[q] * (self.f[index][q] * (self.k1 + 1) / (\n",
    "                        self.f[index][q] + self.k1 * (1 - self.b + self.b * document_len / self.avg_documents_len))) * (\n",
    "                                 qf[q] * (self.k2 + 1) / (qf[q] + self.k2))\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_documents_score(self, query):\n",
    "        score_list = []\n",
    "        for i in range(self.documents_number):\n",
    "            score_list.append(self.get_score(i, query))\n",
    "        return score_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42731429-88d6-4ede-9467-ddc5e9b67ba4",
   "metadata": {},
   "source": [
    "对于国际疾病分类 ICD-10 北京临床版v601标准集进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7094e72-65a6-4f3b-8409-e01261710850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40474\n"
     ]
    }
   ],
   "source": [
    "icd_df = pd.read_excel(\n",
    "    './data/国际疾病分类 ICD-10 北京临床版v601.xlsx',\n",
    "    header=None, \n",
    "    names=['icd_code', 'name'])\n",
    "icd_name = icd_df[\"name\"]\n",
    "print(len(icd_name))\n",
    "with open('./data/train.json', encoding='utf-8') as df:\n",
    "    results = json.load(df)\n",
    "    for result in results :\n",
    "        norm_lists = clean(result.get('normalized_result')).split('##')\n",
    "        for norm_list in norm_lists:   \n",
    "            where_res=np.where(icd_name==norm_list)\n",
    "            if len(where_res[0]) == 0 :\n",
    "                icd_name = np.append(icd_name,norm_list)\n",
    "sentence1 = []\n",
    "norm_text = []\n",
    "with open('./data/dev.json', encoding='utf-8') as df:\n",
    "    results = json.load(df)\n",
    "    for result in results :\n",
    "        text = clean(result.get('text'))\n",
    "        norm_lists = clean(result.get('normalized_result')).split('##')\n",
    "        norm_text.append(norm_lists)\n",
    "        sentence1.append(text)\n",
    "        for norm_list in norm_lists:   \n",
    "            where_res=np.where(icd_name==norm_list)\n",
    "            if len(where_res[0]) == 0 :\n",
    "                icd_name = np.append(icd_name,norm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ffa746-08ca-4e5d-bbc9-dc07ef5b2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.572 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "document_name = [list(jieba.cut(t)) for t in icd_name]\n",
    "bm25_model = BM25_Model(document_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204351a7-6440-4547-a99a-21a1b1cd4ccc",
   "metadata": {},
   "source": [
    "导入之前训练的SimCSE模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1164b8b7-3ecf-4b71-8b07-d355639ecaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "class SimcseModel(nn.Module):\n",
    "    \"\"\"Simcse有监督模型定义\"\"\"\n",
    "    def __init__(self, pretrained_model: str, pooling: str):\n",
    "        super(SimcseModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model)\n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
    "        return out.last_hidden_state[:, 0]  # [batch, 768]\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "POOLING = 'cls'  \n",
    "# 预训练模型目录\n",
    "model_path = 'hfl/chinese-roberta-wwm-ext'\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING)\n",
    "model.load_state_dict(torch.load(\"./simcse_sup.pt\"))\n",
    "model.to(DEVICE)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d91f47f-00d0-4301-bfae-5b63c6f9d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "MAXLEN = 64\n",
    "def encode(model,text):\n",
    "    model.eval()\n",
    "    source = tokenizer(text, max_length=MAXLEN, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    source_input_ids = source['input_ids'].squeeze(1).to(DEVICE)\n",
    "    source_attention_mask = source['attention_mask'].squeeze(1).to(DEVICE)\n",
    "    source_token_type_ids = source['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "    source_pred = model(source_input_ids, source_attention_mask, source_token_type_ids)\n",
    "    return source_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d8dcaa-e07a-4508-9711-f1179f2496b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "ainfo = []\n",
    "for idx in range(len(sentence1)):\n",
    "    if idx % 100 == 0 :\n",
    "        print(idx)\n",
    "    info = []\n",
    "    with torch.no_grad():\n",
    "        query = list(jieba.cut(sentence1[idx]))\n",
    "        scores = bm25_model.get_documents_score(query)\n",
    "        results = zip(range(len(scores)), scores)\n",
    "        results = sorted(results, key=lambda x: x[1],reverse=True)\n",
    "        query_emb = encode(model,sentence1[idx])\n",
    "        scores_sim = []\n",
    "        for num,score in results[0:400]:\n",
    "            sen1 = encode(model,icd_name[num])\n",
    "            sim = F.cosine_similarity(query_emb, sen1, dim=-1)\n",
    "            scores_sim.append(sim)\n",
    "        results_sim = zip(range(len(scores_sim)), scores_sim)\n",
    "        results_sim = sorted(results_sim, key=lambda x: x[1],reverse=True)\n",
    "        se = \"\"\n",
    "        for num , score in results_sim[0:2]:\n",
    "            if  results_sim[0][1] <= 0.91:\n",
    "                se = str(icd_name[results[num][0]])\n",
    "                break\n",
    "            else :\n",
    "                if score > 0.91:\n",
    "                    se = se +\"##\"+ str(icd_name[results[num][0]])\n",
    "        info.append(sentence1[idx])\n",
    "        info.append(se)\n",
    "        ainfo.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "303b9863-5804-4cb5-ab90-a2d7765ee9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.DataFrame(ainfo, columns=['text','norm_text'])\n",
    "data_file.to_csv('test.csv',index=None,encoding='utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
