{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb52123-9200-4b6a-86aa-b25b1b07f1a5",
   "metadata": {},
   "source": [
    "导入所需包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2547643e-ff10-42d8-a725-8e92a8388746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from loguru import logger\n",
    "from scipy.stats import spearmanr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4fcd3-f38a-4a6e-a5c5-b782597a4382",
   "metadata": {},
   "source": [
    "设置基本参数，以及文件读取和存储路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb79d48b-8b59-4132-986e-893da54344ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-5\n",
    "MAXLEN = 64\n",
    "POOLING = 'cls'   # choose in ['cls', 'pooler', 'last-avg', 'first-last-avg']\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "# 预训练模型目录\n",
    "model_path = 'hfl/chinese-roberta-wwm-ext'\n",
    "\n",
    "# 微调后参数存放位置\n",
    "SAVE_PATH = './simcse_sup.pt'\n",
    "\n",
    "# 数据位置\n",
    "TRAIN = './ICD_train.txt'\n",
    "DEV = './ICD_dev.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f179136-0caa-4c68-829f-2d89a1dd70a8",
   "metadata": {},
   "source": [
    "数据读取以及装入到dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16eb854-8ddb-4c6f-bc5b-7b20dbec4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name: str, path: str) -> List:\n",
    "    def load_train_data(path):        \n",
    "        with jsonlines.open(path, 'r') as f:\n",
    "            return [(line['origin'], line['entailment'], line['contradiction']) for line in f]\n",
    "        \n",
    "    def load_dev_data(path):\n",
    "        with open(path, 'r', encoding='utf8') as f:            \n",
    "            return [(line.split(\"||\")[0], line.split(\"||\")[1], line.split(\"||\")[2]) for line in f] \n",
    "    if name == 'train':\n",
    "        return load_train_data(path)    \n",
    "    return load_dev_data(path)\n",
    "    \n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data: List):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def text_2_id(self, text: str):\n",
    "        return tokenizer([text[0], text[1], text[2]], max_length=MAXLEN, \n",
    "                         truncation=True, padding='max_length', return_tensors='pt')\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        return self.text_2_id(self.data[index]) \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data: List):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def text_2_id(self, text: str):\n",
    "        return tokenizer(text, max_length=MAXLEN, truncation=True, \n",
    "                         padding='max_length', return_tensors='pt')\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        line = self.data[index]\n",
    "        return self.text_2_id([line[0]]), self.text_2_id([line[1]]), int(line[2].replace('\"\\n',''))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037868c2-a3f8-4c3a-8849-3506a58e6d3f",
   "metadata": {},
   "source": [
    "模型以及损失函数，这里采用SimCSE有监督版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f042672-cfeb-4c1d-b489-1f98b1c367ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimcseModel(nn.Module):\n",
    "    def __init__(self, pretrained_model: str, pooling: str):\n",
    "        super(SimcseModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model)\n",
    "        self.pooling = pooling\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
    "        return out.last_hidden_state[:, 0] \n",
    "                  \n",
    "            \n",
    "def simcse_sup_loss(y_pred: 'tensor') -> 'tensor':\n",
    "    y_true = torch.arange(y_pred.shape[0], device=DEVICE)\n",
    "    use_row = torch.where((y_true + 1) % 3 != 0)[0]\n",
    "    y_true = (use_row - use_row % 3 * 2) + 1\n",
    "    # batch内两两计算相似度, 得到相似度矩阵(对角矩阵)\n",
    "    sim = F.cosine_similarity(y_pred.unsqueeze(1), y_pred.unsqueeze(0), dim=-1)\n",
    "    # 将相似度矩阵对角线置为很小的值, 消除自身的影响\n",
    "    sim = sim - torch.eye(y_pred.shape[0], device=DEVICE) * 1e12\n",
    "    # 选取有效的行\n",
    "    sim = torch.index_select(sim, 0, use_row)\n",
    "    # 相似度矩阵除以温度系数\n",
    "    sim = sim / 0.05\n",
    "    # 计算相似度矩阵与y_true的交叉熵损失\n",
    "    loss = F.cross_entropy(sim, y_true)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd57f7f-e6cd-48a6-bcf7-2cf87f8de5b6",
   "metadata": {},
   "source": [
    "评估函数，数据来自data_process构建的验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119a3463-ab45-4cc1-add4-e2e798dce3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader) -> float:\n",
    "    model.eval()\n",
    "    label_array = np.array([])\n",
    "    acc = 0 \n",
    "    num = 5896\n",
    "    thresholds = [0.6,0.65,0.7 , 0.75, 0.8,0.85, 0.9,0.95 ]\n",
    "    for threshold in thresholds:\n",
    "        acc_now = 0\n",
    "        with torch.no_grad():\n",
    "            for source, target, label in dataloader:\n",
    "                # source        [batch, 1, seq_len] -> [batch, seq_len]\n",
    "                source_input_ids = source['input_ids'].squeeze(1).to(DEVICE)\n",
    "                source_attention_mask = source['attention_mask'].squeeze(1).to(DEVICE)\n",
    "                source_token_type_ids = source['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                source_pred = model(source_input_ids, source_attention_mask, source_token_type_ids)\n",
    "                # target        [batch, 1, seq_len] -> [batch, seq_len]\n",
    "                target_input_ids = target['input_ids'].squeeze(1).to(DEVICE)\n",
    "                target_attention_mask = target['attention_mask'].squeeze(1).to(DEVICE)\n",
    "                target_token_type_ids = target['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                target_pred = model(target_input_ids, target_attention_mask, target_token_type_ids)\n",
    "                # concat\n",
    "                sim = F.cosine_similarity(source_pred, target_pred, dim=-1)\n",
    "        # corrcoef  \n",
    "                sim_numpy = sim.cpu().numpy()\n",
    "                sim_n = np.array([])\n",
    "                for s,l in zip(sim_numpy,label):\n",
    "                    if s >= threshold :\n",
    "                        sim_n = np.append(sim_n,1)\n",
    "                    else :\n",
    "                        sim_n = np.append(sim_n,0)\n",
    "                acc_now = acc_now + np.count_nonzero(sim_n==label.cpu().numpy())\n",
    "            acc = max (acc , acc_now)\n",
    "    print(acc/num)\n",
    "    return acc/num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a923906-95ab-4e17-b78c-6dcfdae47e38",
   "metadata": {},
   "source": [
    "模型训练函数，其下游任务为评估验证集准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573b50fc-63b5-4c7a-966a-e511099ec1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, dev_dl, optimizer) -> None:\n",
    "    model.train()\n",
    "    global best\n",
    "    early_stop_batch = 0\n",
    "    for batch_idx, source in enumerate(tqdm(train_dl), start=1):\n",
    "        real_batch_num = source.get('input_ids').shape[0]\n",
    "        input_ids = source.get('input_ids').view(real_batch_num * 3, -1).to(DEVICE)\n",
    "        attention_mask = source.get('attention_mask').view(real_batch_num * 3, -1).to(DEVICE)\n",
    "        token_type_ids = source.get('token_type_ids').view(real_batch_num * 3, -1).to(DEVICE)\n",
    "        # 训练\n",
    "        out = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss = simcse_sup_loss(out)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 评估\n",
    "        if batch_idx % 10 == 0:\n",
    "            logger.info(f'loss: {loss.item():.4f}')\n",
    "            corrcoef = eval(model, dev_dl)\n",
    "            model.train()\n",
    "            if best < corrcoef:\n",
    "                early_stop_batch = 0\n",
    "                best = corrcoef\n",
    "                torch.save(model.state_dict(), SAVE_PATH)\n",
    "                logger.info(f\"higher corrcoef: {best:.4f} in batch: {batch_idx}, save model\")\n",
    "                continue\n",
    "            early_stop_batch += 1\n",
    "            if early_stop_batch == 100:\n",
    "                logger.info(f\"corrcoef doesn't improve for {early_stop_batch} batch, early stop!\")\n",
    "                logger.info(f\"train use sample number: {(batch_idx - 10) * BATCH_SIZE}\")\n",
    "                return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec733e9a-f168-4954-888b-930c84cda43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:40:36.798 | INFO     | __main__:<cell line: 1>:1 - device: cuda, pooling: cls, model path: hfl/chinese-roberta-wwm-ext\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ok \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-10-15 16:40:49.353 | INFO     | __main__:<cell line: 19>:20 - epoch: 0\n",
      "  7%|▋         | 9/125 [00:03<00:38,  2.99it/s]2022-10-15 16:40:52.722 | INFO     | __main__:train:18 - loss: 2.0937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9377544097693351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:42:08.967 | INFO     | __main__:train:25 - higher corrcoef: 0.9378 in batch: 10, save model\n",
      " 15%|█▌        | 19/125 [01:22<02:13,  1.26s/it]2022-10-15 16:42:12.278 | INFO     | __main__:train:18 - loss: 1.7977\n",
      " 16%|█▌        | 20/125 [02:37<41:04, 23.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9372455902306649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 29/125 [02:40<02:01,  1.26s/it]2022-10-15 16:43:30.530 | INFO     | __main__:train:18 - loss: 1.8531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939280868385346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:44:47.031 | INFO     | __main__:train:25 - higher corrcoef: 0.9393 in batch: 30, save model\n",
      " 31%|███       | 39/125 [04:00<01:50,  1.28s/it]2022-10-15 16:44:50.372 | INFO     | __main__:train:18 - loss: 2.0553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9404681139755766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:46:06.903 | INFO     | __main__:train:25 - higher corrcoef: 0.9405 in batch: 40, save model\n",
      " 39%|███▉      | 49/125 [05:20<01:37,  1.29s/it]2022-10-15 16:46:10.227 | INFO     | __main__:train:18 - loss: 1.8556\n",
      " 40%|████      | 50/125 [06:36<29:27, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9363975576662144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 59/125 [06:39<01:23,  1.27s/it]2022-10-15 16:47:28.784 | INFO     | __main__:train:18 - loss: 1.7279\n",
      " 48%|████▊     | 60/125 [07:54<25:32, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9319877883310719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 69/125 [07:57<01:11,  1.27s/it]2022-10-15 16:48:47.425 | INFO     | __main__:train:18 - loss: 1.4673\n",
      " 56%|█████▌    | 70/125 [09:13<21:40, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9328358208955224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 79/125 [09:16<00:58,  1.27s/it]2022-10-15 16:50:06.266 | INFO     | __main__:train:18 - loss: 1.2773\n",
      " 64%|██████▍   | 80/125 [10:33<18:00, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9279172320217096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 89/125 [10:37<00:48,  1.35s/it]2022-10-15 16:51:27.087 | INFO     | __main__:train:18 - loss: 1.1707\n",
      " 72%|███████▏  | 90/125 [12:06<16:09, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9248643147896879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 99/125 [12:10<00:38,  1.50s/it]2022-10-15 16:52:59.946 | INFO     | __main__:train:18 - loss: 1.5506\n",
      " 80%|████████  | 100/125 [13:39<11:35, 27.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9268995929443691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 109/125 [13:42<00:24,  1.50s/it]2022-10-15 16:54:32.757 | INFO     | __main__:train:18 - loss: 1.2010\n",
      " 88%|████████▊ | 110/125 [15:12<06:57, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9241858887381276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 119/125 [15:15<00:09,  1.51s/it]2022-10-15 16:56:05.578 | INFO     | __main__:train:18 - loss: 1.7988\n",
      " 96%|█████████▌| 120/125 [16:44<02:18, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926729986431479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [16:46<00:00,  8.06s/it]\n",
      "2022-10-15 16:57:36.274 | INFO     | __main__:<cell line: 19>:22 - train is finished, best model is saved at ./simcse_sup.pt\n",
      "2022-10-15 16:57:36.276 | INFO     | __main__:<cell line: 19>:20 - epoch: 1\n",
      "  7%|▋         | 9/125 [00:03<00:47,  2.46it/s]2022-10-15 16:57:40.305 | INFO     | __main__:train:18 - loss: 1.1276\n",
      "  8%|▊         | 10/125 [01:32<53:17, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9262211668928086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 19/125 [01:36<02:37,  1.48s/it]2022-10-15 16:59:13.147 | INFO     | __main__:train:18 - loss: 1.1017\n",
      " 16%|█▌        | 20/125 [03:05<48:40, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9277476255088195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 29/125 [03:09<02:25,  1.51s/it]2022-10-15 17:00:46.029 | INFO     | __main__:train:18 - loss: 1.1668\n",
      " 24%|██▍       | 30/125 [04:38<44:02, 27.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9255427408412483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 39/125 [04:42<02:10,  1.52s/it]2022-10-15 17:02:18.904 | INFO     | __main__:train:18 - loss: 1.6453\n",
      " 32%|███▏      | 40/125 [06:11<39:18, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9274084124830394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 49/125 [06:14<01:54,  1.51s/it]2022-10-15 17:03:51.576 | INFO     | __main__:train:18 - loss: 1.3329\n",
      " 40%|████      | 50/125 [07:43<34:43, 27.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9255427408412483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 59/125 [07:47<01:40,  1.52s/it]2022-10-15 17:05:24.315 | INFO     | __main__:train:18 - loss: 1.3684\n",
      " 48%|████▊     | 60/125 [09:16<30:06, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216417910447762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 69/125 [09:20<01:24,  1.50s/it]2022-10-15 17:06:57.084 | INFO     | __main__:train:18 - loss: 1.1348\n",
      " 56%|█████▌    | 70/125 [10:49<25:29, 27.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9238466757123474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 79/125 [10:53<01:08,  1.50s/it]2022-10-15 17:08:29.843 | INFO     | __main__:train:18 - loss: 0.9873\n",
      " 64%|██████▍   | 80/125 [12:22<20:49, 27.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9170624151967436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 89/125 [12:25<00:54,  1.51s/it]2022-10-15 17:10:02.603 | INFO     | __main__:train:18 - loss: 0.9899\n",
      " 72%|███████▏  | 90/125 [13:55<16:13, 27.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9170624151967436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 99/125 [13:58<00:39,  1.52s/it]2022-10-15 17:11:35.485 | INFO     | __main__:train:18 - loss: 1.2397\n",
      " 80%|████████  | 100/125 [15:27<11:34, 27.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9151967435549525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 109/125 [15:31<00:24,  1.51s/it]2022-10-15 17:13:08.171 | INFO     | __main__:train:18 - loss: 0.8929\n",
      " 88%|████████▊ | 110/125 [17:00<06:57, 27.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9190976933514247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 119/125 [17:04<00:09,  1.51s/it]2022-10-15 17:14:41.051 | INFO     | __main__:train:18 - loss: 1.3644\n",
      " 96%|█████████▌| 120/125 [18:33<02:19, 27.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185888738127544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [18:35<00:00,  8.92s/it]\n",
      "2022-10-15 17:16:11.817 | INFO     | __main__:<cell line: 19>:22 - train is finished, best model is saved at ./simcse_sup.pt\n",
      "2022-10-15 17:17:41.020 | INFO     | __main__:<cell line: 27>:27 - dev_corrcoef: 0.9405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9404681139755766\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'device: {DEVICE}, pooling: {POOLING}, model path: {model_path}')\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "#加载数据\n",
    "train_data = load_data('train',TRAIN)\n",
    "random.shuffle(train_data)                        \n",
    "dev_data = load_data('dev',DEV) \n",
    "train_dataloader = DataLoader(TrainDataset(train_data), batch_size=BATCH_SIZE)\n",
    "dev_dataloader = DataLoader(TestDataset(dev_data), batch_size=BATCH_SIZE)\n",
    "print(\"data ok \")\n",
    "\n",
    "#加载模型\n",
    "model = SimcseModel(pretrained_model=model_path, pooling=POOLING)\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    \n",
    "# 训练\n",
    "best = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    logger.info(f'epoch: {epoch}')\n",
    "    train(model, train_dataloader, dev_dataloader, optimizer)\n",
    "    logger.info(f'train is finished, best model is saved at {SAVE_PATH}')\n",
    "\n",
    "#验证\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "dev_corrcoef = eval(model, dev_dataloader)\n",
    "logger.info(f'dev_corrcoef: {dev_corrcoef:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
